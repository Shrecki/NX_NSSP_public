{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56e54670",
   "metadata": {},
   "source": [
    "<img src=\"https://www.epfl.ch/about/overview/wp-content/uploads/2020/07/logo-epfl-1024x576.png\" style=\"padding-right:10px;width:140px;float:left\"></td>\n",
    "<h2 style=\\\"white-space: nowrap\\\">Neural Signals and Signal Processing (NX-421)</h2>\n",
    "<hr style=\\\"clear:both\\\"></hr>\n",
    "<h1><font color='black'>Laboratory exercise: Basics of the General Linear Model</font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469af8e5",
   "metadata": {},
   "source": [
    "## 0. Additional packages\n",
    "For this lab, we will require some packages!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e72062c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "#####################\n",
    "# Import of utils.py functions\n",
    "#####################\n",
    "# Required to get utils.py and access its functions\n",
    "notebook_dir = os.path.abspath(\"\")\n",
    "parent_dir = os.path.abspath(os.path.join(notebook_dir, '..'))\n",
    "sys.path.append(parent_dir)\n",
    "sys.path.append('.')\n",
    "from utils import loadFSL, FSLeyesServer, mkdir_no_exist, interactive_MCQ\n",
    "\n",
    "#############################\n",
    "# Loading fsl and freesurfer within Neurodesk\n",
    "# You can find the list of available other modules by clicking on the \"Softwares\" tab on the left\n",
    "#############################\n",
    "import lmod\n",
    "await lmod.purge(force=True)\n",
    "await lmod.load('fsl/6.0.7.4')\n",
    "await lmod.load('freesurfer/7.4.1')\n",
    "await lmod.list()\n",
    "\n",
    "####################\n",
    "# Setup FSL path\n",
    "####################\n",
    "loadFSL()\n",
    "\n",
    "####################\n",
    "# DIPY_HOME should be set prior to import of dipy to make sure all downloads point to the right folder\n",
    "####################\n",
    "os.environ[\"DIPY_HOME\"] = \"/home/jovyan/Data\"\n",
    "\n",
    "###################\n",
    "# Load other relevant libraries for the lab\n",
    "##################\n",
    "import fsl.wrappers, statsmodels\n",
    "from fsl.wrappers import fslmaths\n",
    "import dipy\n",
    "import os.path as op\n",
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7c1215-37da-4f76-909e-965355a85a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui wx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c66664f-f8e8-43e5-afc9-c367385a5c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "# Start FSLeyes (very neat tool to visualize MRI data of all sorts) within Python\n",
    "################\n",
    "fsleyesDisplay = FSLeyesServer()\n",
    "fsleyesDisplay.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b2480c",
   "metadata": {},
   "source": [
    "# 1. Fixed effect or random effect?\n",
    "\n",
    "\n",
    "<br>\n",
    "<div class=\"warning\" style='background-color:#90EE90; color: #805AD5; border-left: solid #805AD5 4px; border-radius: 4px; padding:0.7em;'>\n",
    "    <span>\n",
    "        <p style='margin-top:1em; text-align:center'><b>What are linear mixed models and why are they useful? </b></p>\n",
    "        <p style='text-indent: 10px;'> Suppose you have a study where you want to evaluate the effect of a drug on a group of patients from several hospitals, assuming a linear relationship between the dose of the drug and its effect, which could be very well captured by a linear model. In this case, the response of the patients to treatments might vary not only in relation to the drug, but also to the hospitals the patients are from (because for instance the hospitals with better facilities and services might favor better responses of the patients to the treatment). To account for this aspect properly, you also need to introduce the hospital as a model variable. \n",
    "            \n",
    "One question to ask yourself at this point is if you want your model to be only predict treatment effect from for patients of the hospitals you are using to build your model or, in principle, be also able to predict the response from patients from any hospital in the world. \n",
    "\n",
    "In the first case, you can simply add the hospital as a categorical variable (a **fixed factor**)to the model, but you will not be able to use the model to predict the response of patients from new hospitals. Note that this approach can still be perfectly valid! Consider specific studies that may be limited to a specific set of hospitals you want to focus on. \n",
    "\n",
    "The idea behind linear mixed models (LMM) is instead to be able to to use the model to predict responses from patients in potentially different hospitals from the one you used to build your model so we would say that is hospital are treated as **random factor**. One first way to visualize and generalyze this concept is to see hospitals as 'levels', and to think about LMM as models that allow to do prediction on levels potentially unseen during the model parameter estimation. \n",
    "\n",
    "You will soon understand this concept better and we will see together several examples and apply LMM also to fMRI. Let's start with some useful terminology, and make some other examples to further strengthen the concept.\n",
    "            <br><br></p>\n",
    "        <u>Fixed factor</u>: You have gathered data for all levels (values) of interest for the variable (factor) of interest. <br>Here are some <u>fixed factors</u>:\n",
    "        <ul>\n",
    "            <li>A study wishes to compare smokers and non smokers. You've gathered data between smokers and non smokers to this end. Because there are no other possible categories, the smoking variable is a fixed factor: you have measurements of all observable values!\n",
    "            </li>\n",
    "            <li>A study quantifies the effect of 3 different dosages, and you've acquired repeated measurement for these 3 dosages. Because you have data for all levels of interest <i>and you do not want to say anything about other dosages</i>, this is a fixed factor.\n",
    "            </li>\n",
    "            <li>A study wishes to compare two car models, Ferori and Lamb'orgini to see which car model among the two might have fastest acceleration. You gather data from both models. Because your aim is to study only the two car models and because you have measurement for both, the car models is a fixed factor.\n",
    "            </li>\n",
    "        </ul>\n",
    "        <br><br><u>Random factor</u>: The factor has many possible levels (values) and you're interested in all of them, but only a random sample of levels is included in the data.\n",
    "        <br>Here are some <u>random factors</u>:\n",
    "        <ul>\n",
    "            <li>\n",
    "                A study wishes to assess the effect of car model on car speed. To this end, a random sample of car models is selected. In this case, the question is not which model is fastest, but what variability in car speed can be attributed to the model itself.\n",
    "            </li>\n",
    "            <li>A study wishes to compare two surgical procedures on horses. We train seven different vet teams in both procedures (so as to make them comparable) and make them perform an equal number of procedures. In this case, we want a statement about the surgery, regardless of the vet teams performing it. We must generalize our findings to the entire vet population; as a consequence, we must consider that the seven teams we have are but possible levels in the entire population of existing vet teams: this is a random factor.</li>\n",
    "        </ul>\n",
    "    </span>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7e2efa",
   "metadata": {},
   "source": [
    "<div class=\"warning\" style='background-color:#805AD5; color: #90EE90; border-left: solid #805AD5 4px; border-radius: 4px; padding:0.7em;'>\n",
    "    <span>\n",
    "    <p style='margin-top:1em; text-align:center'>\n",
    "    <b>Why random effects matter: ⚠️ pseudoreplication ⚠️</b></p>\n",
    "    <p style='text-indent: 10px;'> Pseudoreplication happens when observations are not statistically independent but are treated as though they are. We must take care of these assumptions in the modelling, otherwise the math breaks down.<br> Consider the case of the smoker study. You gather for each participant 10 measurements, to alleviate measurement error, which is fine but...clearly measurements of a single participant are no longer independent. Blood pressure of a participant on average will differ from another one for reasons perhaps unrelated to smoking, so independence no longer holds! <br></p>\n",
    "        <p style='text-indent: 10px;'>The participant variable is clearly a random factor. To account for the effect of smoking, you therefore want to make a claim on the population of smokers against non smokers: you <u>must</u> account for the random effect of participants, otherwise your findings will not be valid.</p>\n",
    "        <p style='text-indent: 10px;'>In fact, random effects can arise from even more subtle effects. What if half your participants have their blood pressure measured by nurse A and the other half by nurse B? We're not interested in comparing the performance of these particular nurses, but we'd like to have a statement of smoking, regardless of the nurse measuring blood pressure.\n",
    "    </p>\n",
    "    </span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2385242",
   "metadata": {},
   "source": [
    "Now that you are hopefully more clear on what fixed effect and random effect might mean, you might wonder how we can account for both random and fixed effects? Mixed models do precisely this! Let's have a look at a practical example to make it all a bit clearer :) First of all, formally here is a linear mixed model:\n",
    "<img src=\"imgs/lmm.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c09f01",
   "metadata": {},
   "source": [
    "Let's stop for a moment. The random effect coefficients have an associated mean and covariance matrix (which maps back to their random behaviour, if you will :) ). Usually, one assumes these vectors to follow a gaussian distribution. As you can see from the above expression, this model really tries to disentangle on one side the effect of the random factors, on the other side the effect of the fixed factors. Assume we give you such a model to distinguish between the two-surgeries example above, with X being a matrix describing for every data point whether it was acquired for surgery 1 or surgery 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2e23b9-df76-4a15-b2e6-3ac037d6f78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_MCQ(5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d9af71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1539973a",
   "metadata": {},
   "source": [
    "### 1.1 Application: is my pig getting fat?\n",
    "\n",
    "Imagine we own several pigs, and our pigs just love to climb on their special piggy-couch. Unfortunately, this couch can only support a weight up to 100 kgs (it is a very fragile couch). Knowing that our pigs will soon have piglets, we wonder if we need to invest in a new couch model or if it can support a pig throughout its life.\n",
    "<img src=\"imgs/pig_couch.jpg\"/>\n",
    "<center><i>Finally a research question of relevant clinical application!</i></center>\n",
    "\n",
    "To go about it, you first decide that you will need a critical information: how pigs tend to grow over time. Since we are expecting new piglets in the family very soon, clearly we want an information on the entire population and not just our current pigs. For simplicity, you decide to ignore other factors such as the variability in the food you give them (which you did not record).\n",
    "You assign every pig an id, to more easily differentiate them, and record twelve timepoints of growth for every one of your pigs, twice per year as pigs are fully grown by 6 years of age. The data is summarized below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507ed3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sm.datasets.get_rdataset(\"dietox\", \"geepack\").data\n",
    "data[[\"Pig\", \"Time\", \"Weight\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bbc9ff-faf7-4e8e-b327-4d97f49a6268",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for k in data[\"Pig\"].unique():\n",
    "    weights = data[data[\"Pig\"]==k][\"Weight\"]\n",
    "    time = data[data[\"Pig\"]==k][\"Time\"]\n",
    "    plt.plot(time/2, weights)\n",
    "plt.xlabel(\"Time (Year)\")\n",
    "plt.ylabel(\"Weight (Kg)\")\n",
    "plt.title(\"Pig weight for all pigs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c49d14",
   "metadata": {},
   "source": [
    "As you can see, between all pigs, the trend is similar (weight increases), but they do not have the same exact intercept nor the same exact slope. In other words:\n",
    "- A given pig has its own variance in initial weight\n",
    "- A given pig has its own variance in weight increase\n",
    "\n",
    "Thinking about the sources of variance is very important when designing a model. What we really mean is that the \"weight\" variable has two sources of variance: one is due to time, because as time increases so too do pigs. This variance is called \"within-subject\". We could look at the variance of each pig separately.\n",
    "\n",
    "But to get a good statistical confidence in our recovered values, we need to also consider the variance between pigs: this is the \"between-subject\" variance.\n",
    "\n",
    "Separating these sources is important. For example, consider fur length in dog breeds: clearly if you mix subject variability and breeds, you might reach a wrong conclusion.\n",
    "To answer this question, let's use a mixed model. For this, please fill in the cells below, to indicate which quantity is what in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411ab2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "observations_var =  ##????\n",
    "fixed_effect_var =  ##????\n",
    "random_effect_var = #????"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7965f03d",
   "metadata": {},
   "source": [
    "Let us fit the model now, shall we? We first fit the LMM with appropriate fixed and random effects and then the linear regression model without random effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044505af",
   "metadata": {},
   "outputs": [],
   "source": [
    "md = smf.mixedlm(\"{} ~ {}\".format(observations_var, fixed_effect_var), data, groups=data[random_effect_var], re_formula=\"~{}\".format(fixed_effect_var))\n",
    "mdf = md.fit(method=[\"lbfgs\"])\n",
    "mdf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3254c61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fm = smf.ols(\"{} ~ {}\".format(observations_var, fixed_effect_var),data)\n",
    "fm = fm.fit()\n",
    "fm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881fd83f",
   "metadata": {},
   "source": [
    "We ran two models above. One assumes a random intercept and random slope for each pig: in other words, each pigs has its own growth-rate and initial weight baked in. The other one attempts to model only the effect of time.\n",
    "\n",
    "The **mean** values estimated will not change much, if at all. Inspect the above two, for the OLS Regression (Fixed effect model) and the MixedLM (Random + Fixed effect model). Look at the coefficient for the Let us fit the model now, shall we? We first fir the LMM with appropriate fixed and random effects and then the linear regression model without random effects. Focus in particular on the coefficients columns to see how they change across models and time: they are nearly the same! \n",
    "\n",
    "\n",
    "Based only on the information in the **fixed model**, what would be the expected weight of a pig at the 12th timepoint ? Would the couch endure it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca0ad11",
   "metadata": {},
   "outputs": [],
   "source": [
    "##???? Try to compute the expected weight using the coefficients from the model!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc37933",
   "metadata": {},
   "source": [
    "But wait! That can't be right, can it? Recall the weights we plotted above: we **know for a fact** that some pigs are above 100kgs.\n",
    "\n",
    "<img src=\"imgs/impossible.jpg\"/>\n",
    "\n",
    "That's because we only considered the **mean**. The fixed effect has lost information about the different pigs, and we cannot consider a more meaningful approach of *maximal weight* (ie: fattest pig in our sample).\n",
    "\n",
    "Indeed, what we did with the fixed approach was to compute the weight w as:\n",
    "$$ w = w_{intercept} + t_{slope} * 12 $$\n",
    "\n",
    "Or rewritten:\n",
    "$$ w = w_{fixed} + t_{fixed} * 12 $$\n",
    "\n",
    "But we could instead consider the mixed model as:\n",
    "\n",
    "$$ w = w_{fixed} + w_{random} + t_{fixed} * 12 + t_{random} * 12 = w_{fixed} + w_{random} + (t_{fixed} + t_{random}) * 12$$\n",
    "\n",
    "For this, let's get the random slope of our fattest growing pig and likewise fattest piglet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537e35ea-9a8b-4d40-8dd8-8059d08a143f",
   "metadata": {},
   "outputs": [],
   "source": [
    "intercepts = []\n",
    "time = []\n",
    "for x in list(mdf.random_effects.values()):\n",
    "    # We combine both the group intercept and the fixed effect intercept to get the participant's actual intercept\n",
    "    intercepts.append(x['Group'] + mdf.fe_params['Intercept'])\n",
    "    # Likewise\n",
    "    time.append(x['Time'] + mdf.fe_params['Time'])\n",
    "biggest_intercept = max(intercepts)\n",
    "biggest_time = max(time)\n",
    "\n",
    "print(biggest_intercept)\n",
    "print(biggest_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b406a7d",
   "metadata": {},
   "source": [
    "Based on the found intercept and time coefficient, assume you were offered to either keep your couch or to choose now instead a 130 kgs-supporting couch. Which one would be closer to the *worst-case* weight? (In other words, which couch would minimize the weight error?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6879c9-2bd3-4f26-92c2-d18d99ac1942",
   "metadata": {},
   "outputs": [],
   "source": [
    "##???? Try to compute it using the appropriate intercept and time!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f1bb8e",
   "metadata": {},
   "source": [
    "### 1.2. Where are the design matrices?\n",
    "In the example above, we simply gave you the data. You had to decide the variables to set as fixed effect and random effect, but that's it. In practice, you will often have to think about the design matrices themselves, which relate to your experimental design. Let's think about it for a bit and break down our design for the above experiment in appropriate matrices.<br>\n",
    "First off, the observations. Each observation is a single scalar: the weight of pig i at time k:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba566f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2911da-0120-4c89-9078-3acf8d9f8f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_MCQ(5,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f51c483",
   "metadata": {},
   "source": [
    "*Hint: Think of what we are trying to express! Intuitively, we say that weight = timepoint x coefficient + pig category x another coefficient + modeling noise*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9475b9a9",
   "metadata": {},
   "source": [
    "Now, how do we make the design matrix? Well, it is very simple. For each fixed effect **variable**, we model one column. The lines correspond to the observations.\n",
    "To give you a concrete example, let's imagine that I conduct an experiment. I flip a coin, obtaining head or tail. Depending on the result, I decide to either put my participant in a dark room or in a lit room, and I then record the time this participant takes to fall asleep. My hypothesis is that the presence or absence of light has an impact on this time to sleep (tts). I am also curious about the room temperature, and decide to model three temperatures: \n",
    "- 1°C\n",
    "- 19°C\n",
    "- 38°C\n",
    "\n",
    "Note that I do not want a general statement on room temperatures, only these three specific temperatures.\n",
    "\n",
    "Because I am trying lit against dark room and want to test for presence against absence of light for three fixed temperatures, it is clear that the \"light\" condition is a fixed factor. Likewise, the room temperature is also a fixed factor.\n",
    "\n",
    "Here are the observations I gathered for the tts (in seconds):\n",
    "```python\n",
    "tts\n",
    "120\n",
    "135\n",
    "150\n",
    "400\n",
    "517\n",
    "520\n",
    "```\n",
    "\n",
    "I am unfortunately a bit messy. While conducting one of my experiments in the dark, I mess up my documents and shuffle my design matrices with previously considered designs. Here are the matrices I end up with:\n",
    "\n",
    "```python\n",
    "A\n",
    "room lit  temperature\n",
    "0         1°C         \n",
    "0         19°C\n",
    "0         38°C\n",
    "0         1°C\n",
    "0         19°C\n",
    "0         38°C\n",
    "1         1°C\n",
    "1         19°C\n",
    "1         38°C\n",
    "\n",
    "B\n",
    "room lit  temperature\n",
    "0         1°C         \n",
    "0         19°C\n",
    "0         38°C\n",
    "1         1°C\n",
    "1         19°C\n",
    "1         38°C\n",
    "\n",
    "C\n",
    "room lit  temperature\n",
    "0         1°C         \n",
    "0         1°C\n",
    "0         1°C\n",
    "1         1°C\n",
    "1         1°C\n",
    "1         1°C\n",
    "\n",
    "D\n",
    "room lit  temperature\n",
    "0         1°C         \n",
    "0         19°C\n",
    "0         39°C\n",
    "1         1°C\n",
    "1         19°C\n",
    "1         28°C\n",
    "\n",
    "E\n",
    "room lit  temperature 1  temperature 2 temperature 3\n",
    "0         1                 0              0\n",
    "0         0                 1              0\n",
    "0         0                 0              1\n",
    "1         1                 0              0\n",
    "1         0                 1              0\n",
    "1         0                 0              1\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d7660c-5ede-4fcc-9026-20302f6e61a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_MCQ(5,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8100c3f",
   "metadata": {},
   "source": [
    "#### 1.2.1 Dummy coding\n",
    "\n",
    "You might have noticed that A has wrong dimensions and thus cannot lead to the observations. Likewise, D contains temperatures outside of our experimentally allowed values, so it is not valid. C, likewise, models a fixed effect but does not include all potential values of room temperature - wrong for our experiment. But what of the others? Are they valid?\n",
    "\n",
    "The room temperature, in this case, is a categorical variable. In some cases (consider breeds of dogs), there is no clear directionality (for example if I code rottveiler=1 and chow-chow=2, the latter is mathematically higher than the former although there is no clear ordering in reality - even if rated for cuteness). When no clear directionality is involved, you can split the categories as shown in matrix E.\n",
    "Matrix E is basically matrix B rewritten **assuming that temperature has no directionality**. This is not totally true in this case, obviously, but you can see how it is done. For experimental conditions, such as stimuli, directionality is often not expected, so knowing how to move from B to E is useful :)\n",
    "\n",
    "\n",
    "<br>\n",
    "<div class=\"warning\" style='background-color:#90EE90; color: #805AD5; border-left: solid #805AD5 4px; border-radius: 4px; padding:0.7em;'>\n",
    "    <span>\n",
    "        <p style='margin-top:1em; text-align:center'><b>The contrast matrix</b></p>\n",
    "        <p style='text-indent: 10px;'> E is actually what we call a *contrast matrix*. The reason for this is that we have now one $\\beta$ coefficient for each category value in a categorical variable. This means we can now look at the impact of each combination. For example, in the case of breeds of dogs, we can look at the effect of chow-chow against rottveiler, or rottveiler against doberman and so on. This is particularly useful when looking at stimulus conditions in neuroscience, as you'll see in the next sections.</p>\n",
    "    </span>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7936b296",
   "metadata": {},
   "source": [
    "Here's what I remember from memory: I first put the participant in the lit room, and chose decreasing temperature for the room, exploring all temperature settings. I then put the participant in the dark, and chose increasing temperature, exploring all settings. Can you design the dataframe that would correspond to this design matrix? To help you, here is an example, showcasing how you can do matrix D from above:\n",
    "\n",
    "```python\n",
    "matrix_D = pd.DataFrame({'room lit': ['no', 'no', 'no', 'yes', 'yes', 'yes'], 'temperature': [1, 19, 39, 1, 19, 39]})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cb7a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "design_matrix = ??? # Please fill in to create this matrix :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52662b7d",
   "metadata": {},
   "source": [
    "Great! Now you now the basics of a design matrix. As you can see, it is a fairly easy thing to do!\n",
    "Let's move away from our piggies and back to fMRI now!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1db76dd",
   "metadata": {},
   "source": [
    "## 2. Moving from univariate observations to multivariate: the GLM\n",
    "\n",
    "You've seen above that we used a linear model to relate our experimental conditions with the observations.\n",
    "But most of the time (such as in fMRI), our observations are not just a single scalar: they are multivariate quantities. Images consist of several pixels, physical experiments might record multiple different measurements at the same time - and in fMRI we have several voxels per volume.\n",
    "\n",
    "How does the formalism above fare, when we extend to such a scenario? Well, the *General Linear Model* is one way to extend what we've seen to cases of several dimensions and the answer is: it fares nicely.\n",
    "In the case of fMRI, we don't have a single variable: every voxel or brain region is a separate variable, for which we want to solve the system. For this purpose, we need to use what is called a *General Linear Model*.\n",
    "\n",
    "\n",
    "The equation of the GLM you've seen above is still the following:\n",
    "\n",
    "<p style=\"font-size:25px;\">$$Y = X\\beta + Zu + \\epsilon$$</p>\n",
    "\n",
    "The only difference is that now, $\\beta$ and $u$ are matrices and $\\epsilon$ is a vector!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf9f5d6",
   "metadata": {},
   "source": [
    "### 2.1 Analysis levels in fMRI\n",
    "\n",
    "In fMRI it turns out you can actually do the GLM in two steps, called *analysis levels*.\n",
    "\n",
    "The first step is conducted at the individual participant level. It accounts for the fixed effects in your experiment (so $X\\beta$).\n",
    "The higher order analysis is done by aggregating the individual model's results. This second level accounts for the random effect ($Zu$). In general this effect is due to population, but you can imagine different random effects as we discussed previously.\n",
    "\n",
    "We'll now teach you how to apply the GLM, first at the single participant level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6795eccf",
   "metadata": {},
   "source": [
    "### 2.2 Loading the data\n",
    "\n",
    "The GLM should be done on data that have been preprocessed. To save you some time, we'll use data taken from nilearn's <a href=\"### 2.2 Loading the data\n",
    "\n",
    "The GLM should be done on data that have been preprocessed. To save you some time, we'll use data taken from nilearn's <a href=\"https://nilearn.github.io/stable/auto_examples/00_tutorials/plot_single_subject_single_run.html#sphx-glr-auto-examples-00-tutorials-plot-single-subject-single-run-py\">GLM tutorial</a>. Run the cell below to load them!\">GLM tutorial</a>. Run the cell below to load them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa724a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.datasets import fetch_spm_auditory\n",
    "subject_data = fetch_spm_auditory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f756199e",
   "metadata": {},
   "source": [
    "Let's have a look at the data in there! You'll see that the functional data is several images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dd9fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_data.func"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5c8f5a",
   "metadata": {},
   "source": [
    "Many volumes! But what are they, exactly? Let's open one of them to see!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5858cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "from nilearn import plotting \n",
    "\n",
    "imgplot=nib.load(subject_data.func[0])\n",
    "plotting.plot_anat(imgplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2821a05b",
   "metadata": {},
   "source": [
    "As you can see there are all 3D volumes. We need to aggregate them all in a timeserie before we can run our GLM. \n",
    "This can be done easily with nilearn's **concat** function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bafb7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.image import concat_imgs, mean_img\n",
    "fmri_img = concat_imgs(subject_data.func)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd7138b",
   "metadata": {},
   "source": [
    "Great! Let's now load the experimental design. In this experiment, subjects could be in two conditions:\n",
    "- **active**, where they were subjected to **auditory** stimulation\n",
    "- **rest** otherwise\n",
    "\n",
    "We alternated between blocks of each condition, lasting 42 seconds each. Here is the list of these events:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9def7b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = pd.read_table(subject_data['events'])\n",
    "events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d7696c",
   "metadata": {},
   "source": [
    "<div class=\\\"warning\\\" style='background-color:#C1ECFA; color: #112A46; border-left: solid #darkblue 4px; border-radius: 4px; padding:0.7em;'>\n",
    "    <span>\n",
    "    <p style='margin-top:1em; text-align:center'>\n",
    "    <b>💡 Where to find these event files ? 💡</b></p>\n",
    "    <p style='text-indent: 10px;'>\n",
    "    Here we are showing you a nice example, where everything is already nicely put in its place. What if you wanted to load events from say an openneuro dataset? How should you proceed? \n",
    "        Well, let's take a practical example. Go to <a href=\"https://openneuro.org/datasets/ds004226\">this dataset</a> (which should be familiar) and navigate to the func folder of subject sub-001. In there, we see several things, but let's focus on files that end in events.tsv:\n",
    "        <img src=\"imgs/event_files.png\"/>\n",
    "\n",
    "\n",
    "These files are exactly those that contain for each session the events in the appropriate format. As a consequence, you should download them. We give an example cell at the very end of the notebook, as it could be useful for your project :)\n",
    "    </p></span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dea5fbf",
   "metadata": {},
   "source": [
    "This way of specifying the stimulations is pretty standard in fMRI: the software will then construct for you the corresponding design matrix, based on repetition time and other regressors you might want to add. Let's first start with only our regressors of interest, plus noise.\n",
    "\n",
    "In this experiment, the TR of acquisition was **7 seconds**.\n",
    "\n",
    "In the cell below, we specify the model and fit it to our data and events (which is our experimental design, again!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a542f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.glm.first_level import make_first_level_design_matrix, FirstLevelModel\n",
    "\n",
    "# Specify what sort of GLM we want (nature of the noise, repetition time of the data and other parameters)\n",
    "fmri_glm = FirstLevelModel(t_r=7,\n",
    "                           noise_model='ar1',\n",
    "                           standardize=False,\n",
    "                           hrf_model='spm',\n",
    "                           drift_model=None,\n",
    "                           high_pass=.01)\n",
    "\n",
    "# Fit the model to our design and data\n",
    "fmri_glm = fmri_glm.fit(fmri_img, events)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c69f97",
   "metadata": {},
   "source": [
    "Great, let's inspect first the design matrix that the software created for us, shall we?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de6ffba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.plotting import plot_design_matrix\n",
    "plot_design_matrix(fmri_glm.design_matrices_[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c937be",
   "metadata": {},
   "source": [
    "You can see that we have alternating blocks of active and rest conditions, plus a constant. What you  might wonder, however is **why is it not binary**? Well, this has to do with the nature of fMRI. We need to talk about what is called the hemodynamic response function (HRF)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5797693f",
   "metadata": {},
   "source": [
    "## 3. The HRF: neural basis and modelling\n",
    "\n",
    "One core assumption of GLM modelling is that the brain can be modelled as a linear time invariant system (LTI). \n",
    "Informally, it means that when I subject the brain to two stimulations, A and B, the total signal I observe can be decomposed as the sum of the effect of A and the effect of B on the brain.\n",
    "(If you need more information on LTI systems, check out <a href=\"https://www.youtube.com/watch?v=Y8iFJVmSQIk\">this video</a> for example).\n",
    "\n",
    "Just to make it a bit clear anyway, here the example of a very simple LTI system, the function F(x) = x.\n",
    "<br>Clearly $F(inputA) + F(inputB) = F(inputA + inputB)$, so linearity is very easy to check here. Visually, it would look like this:\n",
    "\n",
    "<img src=\"imgs/lti_example.png\"/>\n",
    "\n",
    "The core idea is that the brain is the same in fMRI!\n",
    "When you show first a stimulus A, and then a stimulus B, the brain will have a way of response for each. But the total effect you observe will be the linear combination of response to A and response to B.\n",
    "<br>\n",
    "### 3.1 The impulse response of the brain\n",
    "\n",
    "When the brain is presented with a very brief signal (so brief we can call it an impulse), it will respond with a function that has a very characteristic shape: the HRF. This profile is really typical:\n",
    "<img src=\"imgs/spm_example_resp.png\"/>\n",
    "\n",
    "As you have probably seen in other courses, having the impulse response of a system is very useful. All signals can be decomposed as a weighted sum of impulses. Imagine having this time three impulses, evenly spaced in time. Two of them will be at 0.5 amplitude, while the middle one will be at 1.0 amplitude. At each peak, I can put my HRF times the peak's amplitude. Here's what it would look like:\n",
    "\n",
    "<img src=\"imgs/multiple_inputs_hrf.png\"/>\n",
    "\n",
    "\n",
    "This operation is called a **convolution**. Summing up all response stimulations is how you obtain the above picture.\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "<div class=\"warning\" style='background-color:#90EE90; color: #805AD5; border-left: solid #805AD5 4px; border-radius: 4px; padding:0.7em;'>\n",
    "    <span>\n",
    "        <p style='margin-top:1em; text-align:center'><b>Relevance of the HRF in the GLM</b></p>\n",
    "        <p style='text-indent: 10px;'> \n",
    "            The goal of the GLM is to determine the response of the brain to a given stimulation. In other words, we are trying to find what the **BOLD response** will look like for a given stimulus. What do we know?</p>\n",
    "        <ul>\n",
    "            <li>The stereotypical response function to stimulation (the HRF)</li>\n",
    "            <li>Stimulus timing and type (your experimental design)</li>\n",
    "            <li>The brain output (the fMRI signal)</li>\n",
    "        </ul>\n",
    "        Because the stimuli are inputs to the brain, and the brain is LTI with impulse response being the HRF, what we can do is <b>convolve the stimuli with the HRF</b> and use this new convolved design matrix as input to the GLM. This is EXACTLY what you see in the design matrix below: the signal is no longer constant, because it has been convolved with the HRF!\n",
    "    </span>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6836a788",
   "metadata": {},
   "source": [
    "To drive our point home, let's do the convolution of an experimental condition (rest), which starts at timepoint 0, and will be set to 1 for 42 samples before returning to zero. We will convolve it with the HRF, and compare it with the design matrix.\n",
    "\n",
    "Notice that the HRF takes some time to return to zero!\n",
    "To convince you, let's include thus about 12 timepoints **after** our last stimulation, just to be on the safe side.\n",
    "\n",
    "To do this, let's first create some quantites. We must know the following:\n",
    "\n",
    "- The time of each frame. You will have to create frames, starting from zero and extending to 55 seconds, spaced by 7 seconds (our TR).\n",
    "- The experimental condition start and end: in this case, from 0 to 42, with a value of 1.\n",
    "- The **oversampling** parameter. This is for the stability of the convolution. The idea is simple: we oversample the signal, convolve, and then downsample to go back to our scan times. In your case, the oversampling will be 50 (so we take 50 samples in between scans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369e5a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = ??? # Replace with start time please\n",
    "end_time = ??? # Replace with end of not stimulation but where we want our frame time to end!!\n",
    "tr = ??? # What is our TR?\n",
    "frame_times= np.asarray(list(range(start_time, end_time, tr)))\n",
    "\n",
    "oversampling = 50\n",
    "\n",
    "onset = ??? # Replace with the time at which stimulus starts\n",
    "duration = ??? # Replace with the duration of the stimulus\n",
    "amplitude = ??? # Replace with amplitude of the stimulus during stimulation\n",
    "\n",
    "exp_condition = np.asarray([[onset], [duration], [amplitude]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249908ba",
   "metadata": {},
   "source": [
    "Great! Now, let's oversample our condition, shall we?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5b97cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.glm.first_level.hemodynamic_models import _sample_condition, _resample_regressor, glover_hrf\n",
    "\n",
    "hr_regressor, hr_frame_times = _sample_condition(exp_condition, frame_times, oversampling)\n",
    "\n",
    "plt.plot(hr_frame_times, hr_regressor)\n",
    "plt.xlabel('High res time')\n",
    "plt.title('Frame time length: {} / Total signal length: {}'.format(len(frame_times), len(hr_regressor)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6664b3",
   "metadata": {},
   "source": [
    "Notice that we have indeed oversampled our array. We've also added a bit of negative values: again this is for the stability of the convolution, to make it start from a clean zero signal around boundaries :)\n",
    "\n",
    "Now, we can convolve our HRF with our high resolution regressor. Here it is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c66393",
   "metadata": {},
   "outputs": [],
   "source": [
    "hrf = glover_hrf(tr=tr)\n",
    "conv_reg = np.array([np.convolve(hr_regressor, hrf)[:hr_regressor.size]])\n",
    "\n",
    "plt.plot(hr_frame_times, conv_reg.T)\n",
    "plt.xlabel('High res time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3961a7aa",
   "metadata": {},
   "source": [
    "Nice! It remains to resample to proper resolution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6904cd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "computed_regressors = _resample_regressor(\n",
    "            conv_reg, hr_frame_times, frame_times)\n",
    "\n",
    "plt.plot(frame_times, computed_regressors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a453d4de",
   "metadata": {},
   "source": [
    "How close are we to what was found in the design matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b28800c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fmri_glm.design_matrices_[0]['rest'][:49])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae07154",
   "metadata": {},
   "source": [
    "Not too far off, but there's a difference still, right? Why is that?\n",
    "**Because in the design matrix the regressors are orthogonalized with respect to each other**, hence the disparity you observe. You are hopefully convinced still that convolution with HRF is the reason you observe this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974af3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_design_matrix(fmri_glm.design_matrices_[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98cf2b7",
   "metadata": {},
   "source": [
    "## 4. Using the GLM in fMRI\n",
    "\n",
    "We've taken a big detour to make you really understand what you see in the design matrix and *why* it shows up this way. The GLM from above, still, is fit to your data. I would like to know now, based on this model, which regions of the brain could be associated to the *active* condition **compared to the rest condition**.\n",
    "\n",
    "In other words, we want to **contrast** the active and rest conditions. This is done by building what is - aptly - called a contrast.\n",
    "Remember: in our modelling, what we fitted are the $\\beta$ coefficients. In particular, we will have here three beta vectors:\n",
    "<p style=\"font-size:20px;\">$\\vec{\\beta_{active}}$,  $\\vec{\\beta_{rest}}$,  $\\vec{\\beta_{constant}}$</p>\n",
    "\n",
    "My $\\beta$ matrix would look like this:\n",
    "<p style=\"font-size:20px;\">$$\\beta =\n",
    "\\begin{bmatrix}\n",
    "\\vec{\\beta_{active}}\\\\\n",
    "\\vec{\\beta_{rest}}\\\\\n",
    "\\vec{\\beta_{constant}}\\end{bmatrix}$$\n",
    "</p>\n",
    "\n",
    "If I now wish to compute the effect of active minus rest, obtaining the contrast $c_{active - rest}$, I should thus multiply like so:\n",
    "\n",
    "<p style=\"font-size:20px;\">$$c_{active - rest} = \n",
    "\\begin{bmatrix}\n",
    "1 & -1 & 0\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "\\vec{\\beta_{active}}\\\\\n",
    "\\vec{\\beta_{rest}}\\\\\n",
    "\\vec{\\beta_{constant}}\\end{bmatrix}$$\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a6c177",
   "metadata": {},
   "source": [
    "This is what it means to define a contrast. Let's do it now in practice. First, let's define our conditions. Can you find the vectors necessary to extract the rest and active conditions from the above beta matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a00ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dictionary of the conditions\n",
    "conditions = {\n",
    "    ???, # Specify the np array, e.g. np.array([2, -1, 0]) to extract active\n",
    "    ???, # Specify the np array, e.g. np.array([2, -1, 0]) to extract rest\n",
    "}\n",
    "\n",
    "active_minus_rest = conditions['active'] - conditions['rest']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d53a4ee",
   "metadata": {},
   "source": [
    "If we plot it, it will look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9f208d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.plotting import plot_contrast_matrix\n",
    "plot_contrast_matrix(active_minus_rest, design_matrix=fmri_glm.design_matrices_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0b6098",
   "metadata": {},
   "source": [
    "Now, let's finally compute the contrast! We form a t-statistic, and obtain a z-score map of the beta coefficients of active minus rest like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2045fdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "z_map = fmri_glm.compute_contrast(active_minus_rest,\n",
    "                                  output_type='z_score')\n",
    "\n",
    "nib.save(z_map, 'z_map_uncorrected.nii.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47caef04",
   "metadata": {},
   "source": [
    "Let's visualize it!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7408e171",
   "metadata": {},
   "source": [
    "Nilearn is kind enough to also provide us with visualization tools, so we can do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a67fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.plotting import plot_stat_map\n",
    "from nilearn.image import mean_img\n",
    "mean_img_ = mean_img(fmri_img),\n",
    "plot_stat_map(z_map, bg_img=mean_img_[0], threshold=3.0,\n",
    "              display_mode='z', cut_coords=[-3,37,70], black_bg=True,\n",
    "              title='Active minus Rest (Z>3)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d80c94",
   "metadata": {},
   "source": [
    "### 4.1 A not-so insignificant issue: multiple-comparisons\n",
    "\n",
    "Let's think for a moment. We have a lot of voxels. For each such voxel, we've performed a statistical test to assess if the difference between the two conditions is significant. Yet, we only showed results for an arbitrary visualization threshold, without caring once about the significance or the p-value! \n",
    "\n",
    "The issue with the p-value here is that we conducted *many tests*, one per voxel. You've probably seen in statistics that this increases the odds of a false positive. In other words, regions turn out positive, simply because we've conducted many tests.\n",
    "\n",
    "We need to control for this false-positive rate to have results that would be somewhat sensible. There are different ways to do it. To keep this tutorial simple, you'll use two procedures together:\n",
    "- False discovery rate correction, where we control the expected number of false discoveries\n",
    "- Removing isolated voxels (because the brain is locally smooth, an isolated peak is suspicious)\n",
    "\n",
    "To do so, please fill below the cell with:\n",
    "- Cluster size: any cluster smaller than 10 voxels is to be thrown away\n",
    "- False discovery rate: we will use a threshold at 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7fb0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.glm import threshold_stats_img\n",
    "\n",
    "#Link to threshold_stats_img function documentation\n",
    "#https://nilearn.github.io/dev/modules/generated/nilearn.glm.threshold_stats_img.html\n",
    "\n",
    "cluster_size = ??? # Fill me with the number of voxels for a cluster to be kept\n",
    "fdr_rate = ??? # Fill me with the fdr rate to use!\n",
    "\n",
    "# Here, we apply the FDR correction + threshold\n",
    "clean_map, threshold = threshold_stats_img(z_map, alpha=fdr_rate, height_control='fdr', cluster_threshold=cluster_size)\n",
    "\n",
    "# And this is just to plot here!\n",
    "plot_stat_map(clean_map, bg_img=mean_img_[0], threshold=threshold,\n",
    "              display_mode='z', cut_coords=[-3,37,70], black_bg=True,\n",
    "              title='Active minus Rest (fdr={}, threshold={}), clusters > {} voxels'.format(fdr_rate, threshold, cluster_size))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b0924c",
   "metadata": {},
   "source": [
    "Knowing that the participant was subjected to auditory stimulation, do these results make sense to you?\n",
    "\n",
    "\n",
    "You now all the basics, which was the most painful part! Now that you understand how to move around the design matrix, we'll touch on some small details! :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7dd81b",
   "metadata": {},
   "source": [
    "## 5. Including regressors in the model\n",
    "\n",
    "You know the basics of the first level GLM, which is the most important part.\n",
    "But how should we include additional regressors in the GLM? Let's say I have heart rate for example, how can I bake it into my computations to mitigate hearbeat's effect on my signal?\n",
    "\n",
    "You've guessed it: we go back to our dear design matrix to modify it. In fact in the GLM, this is what you will always be manipulating since your observations are - well - what they are, and the beta coefficients are what you want to estimate.\n",
    "\n",
    "\n",
    "The idea is simple: adding a regressor is simply done by adding a column to the design matrix. Because these regressors are events that confound our signal (they are not part of the experiment and corrupt our estimates), they are called...confounds or no-interest regressors!\n",
    "\n",
    "For the purpose of this tutorial, we will model what is called the signal drift. The idea is simple: over time, the signal might decrease or increase, without relationship to the experimental paradigm itself (think for instance of fatigue). This variation in the mean of the signal over time can be modelled in the GLM to correct for it.\n",
    "Let's create a drift model, and put it as regressor!\n",
    "We will model it as a polynomial of order 3!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca657a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of the drift model:\n",
    "from nilearn.glm.first_level.design_matrix import _make_drift\n",
    "\n",
    "column_values, column_names = _make_drift(drift_model='polynomial', frame_times=np.asarray(list(range(0, 666, 7))), order=3, high_pass=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28e1878",
   "metadata": {},
   "source": [
    "Beautiful! Let's add it to our design matrix, shall we?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52795aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "design_mat = fmri_glm.design_matrices_[0]\n",
    "for (col, name) in zip(column_values.T, column_names):\n",
    "    design_mat[name] = col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c18dac8",
   "metadata": {},
   "source": [
    "The resulting matrix looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c4d9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_design_matrix(design_mat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b96c6b",
   "metadata": {},
   "source": [
    "You see that including additional regressors basically only boils down to updating your design matrix with relevant quantities. As in Nilearn the design matrix is a simple panda dataframe, this is *very* easy :)\n",
    "\n",
    "Now, to fit the GLM with the design matrix is very easy. During fitting, instead of passing the events, we will pass the design matrix, such that this\n",
    "```python\n",
    "some_glm.fit(data, events=event_df)\n",
    "```\n",
    "becomes this instead:\n",
    "```python\n",
    "some_glm.fit(data, design_matrices=[my_design_matrix])\n",
    "```\n",
    "\n",
    "In our case, the function becomes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf0076d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_glm = FirstLevelModel(t_r=7.0, drift_model='None')\n",
    "fit_glm.fit(fmri_img, design_matrices=[design_mat])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2714f90",
   "metadata": {},
   "source": [
    "You now know how to include any regressor in your design matrix!\n",
    "In pratice, we often include as additional columns:\n",
    "- Motion parameters\n",
    "- Derivatives of the motion parameters\n",
    "- Censoring of outlier volumes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afbf745",
   "metadata": {},
   "source": [
    "The censoring deserves at least a mention. Let's say that for my 96 volumes of interest here, every 10th volume I get an outlier because of motion somehow. I could try to make a single regressor for all volumes, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc86c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = np.zeros((96))\n",
    "reg[::10] = 1\n",
    "\n",
    "\n",
    "design_mat_regged = design_mat.copy()\n",
    "design_mat_regged['motion outlier'] = reg\n",
    "\n",
    "plot_design_matrix(design_mat_regged)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e6c796",
   "metadata": {},
   "source": [
    "However, what we want implicitly is to censor the effect of each volume individually.\n",
    "For this reason, when doing **motion outlier regression** like so in the GLM, you will usually add one regressor **per outlying volume**. In this case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1add1815",
   "metadata": {},
   "outputs": [],
   "source": [
    "design_mat_regged = design_mat.copy()\n",
    "\n",
    "for i in range(10):\n",
    "    reg = np.zeros((96,))*0.0\n",
    "    reg[i*10] = 1.0\n",
    "    design_mat_regged['motion outlier#' + str(i+1)] = reg\n",
    "\n",
    "plot_design_matrix(design_mat_regged)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8882adc",
   "metadata": {},
   "source": [
    "## 6. Higher level analysis\n",
    "\n",
    "Now, for the final part (which will be fast, don't worry!) - the higher level analysis.\n",
    "\n",
    "This analysis aims to model the **random effect** of participants onto the effect you measure. In fMRI, the effect is a contrast map. As such, you will feed to the higher level model contrast maps.\n",
    "\n",
    "The above dataset unfortunately does not contain several participants, so we will load another one to have you work on it.\n",
    "\n",
    "In this experiment, participants performed a functional localizer task.\n",
    "Participants are exposed to four types of stimulation:\n",
    "- An auditory voice asks them to perform a mental computation (e.g: \"Compute seventeen minus four\")\n",
    "- A video projected on a screen asks them to perform a mental computation (same example as above)\n",
    "- An auditory voice reads a narrative sentence (e.g: \"A storm is approaching\")\n",
    "- A video projected on the screen displays a narrative sentence\n",
    "\n",
    "A first level GLM has already been run on these data. The contrast that has been created for each participant opposes mental computation (the first two stimuli) to narrative sentence reading/listening.\n",
    "\n",
    "Let us load these contrast maps and look at one of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b960a6-cbf1-4865-afaf-b7a10d439ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import datasets\n",
    "n_samples = 20\n",
    "localizer_dataset = datasets.fetch_localizer_calculation_task(\n",
    "    n_subjects=n_samples, legacy_format=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e644b79a-2972-4b73-97ee-b48a60570926",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsleyesDisplay.resetOverlays()\n",
    "fsleyesDisplay.load(localizer_dataset.cmaps[0])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56b675b",
   "metadata": {},
   "source": [
    "Despite being heavily present in the task, neither visual nor auditory regions pop out, compared to our previous contrast. Why do you think that is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb0cd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505a84f2",
   "metadata": {},
   "source": [
    "Let's now conduct our second level analysis. To do this, we will specify our design matrix. We always need an intercept. Note that you could include here as a second regressor more interesting factors. In an interventional experiment, you could include a regressor to signal which subjects are 'control' and which ones are 'study'. You can also include effects such as the sex of your participants, their age etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f569493",
   "metadata": {},
   "outputs": [],
   "source": [
    "design_matrix = pd.DataFrame([1] * n_samples, columns=['intercept'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61774cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.glm.second_level import SecondLevelModel\n",
    "second_level_model = SecondLevelModel().fit(\n",
    "    localizer_dataset.cmaps, design_matrix=design_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789afdc2",
   "metadata": {},
   "source": [
    "Great! Now we run the following to obtain the contrast at the population level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766da8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_map = second_level_model.compute_contrast(output_type='z_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d05064",
   "metadata": {},
   "source": [
    "Let's see what it looks like shall we?\n",
    "Please, get the clean map by thresholding the above z-map with an FDR with rate 0.05 and cluster size 10!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662dbb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_map, threshold = threshold_stats_img(z_map, alpha=fdr_rate, height_control='fdr', cluster_threshold=cluster_size)\n",
    "\n",
    "# Saving it to disk\n",
    "nib.save(clean_map, 'localizer_population_cleaned_map.nii.gz')\n",
    "\n",
    "# And this is just to plot here!\n",
    "plot_stat_map(clean_map, threshold=threshold,\n",
    "              display_mode='z', cut_coords=[-3,37,70], black_bg=True,\n",
    "              title='Mental comp. minus narrative read/listen. (fdr={}, threshold={}), clusters > {} voxels'.format(fdr_rate, threshold, cluster_size))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50c6f2b",
   "metadata": {},
   "source": [
    "We've saved the map as localizer_population_cleaned_map, so that you can have a look at it in FSLeyes :) Feel free to explore it. Do you think based on what you know of the brain that these patterns make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b0280e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsleyesDisplay.resetOverlays()\n",
    "fsleyesDisplay.load('localizer_population_cleaned_map.nii.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5fee47",
   "metadata": {},
   "source": [
    "## More to explore\n",
    "\n",
    "You have seen the basics of the GLM. However, there are many more things to be covered. The most important one is the experimental design itself. You can read more on what is called event-related against block design <a href=\"https://afni.nimh.nih.gov/pub/dist/HOWTO/howto/ht03_stim/html/stim_background.html\">here</a>.\n",
    "\n",
    "Secondly, we've used one HRF model, but there are other slightly different HRFs you can use instead. You can also conduct smoothing, include various regressors...all these choices are usually driven by the experiment at hand! They are a bit out of scope of this tutorial. For now: you are done! Congratulations!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78cdd2e",
   "metadata": {},
   "source": [
    "## Parenthesis: an example of how to load an event file from openneuro\n",
    "\n",
    "The below cell shows you how to load the event file of run04 of sub-001 in the dataset ds004226 of openneuro (<a href=\"https://openneuro.org/datasets/ds004226/versions/1.0.0\">this dataset)\n",
    "    \n",
    "<img src=\"imgs/event_files_demo.png\"/>\n",
    "    <center><i>This file specifically</i></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d860df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as op\n",
    "from mne.datasets import sample\n",
    "# Useful imports to define the direct download function below\n",
    "import requests\n",
    "import urllib.request\n",
    "from tqdm import tqdm\n",
    "\n",
    "def mkdir_no_exist(path):\n",
    "    if not op.isdir(path):\n",
    "        os.makedirs(path)\n",
    "        \n",
    "class DownloadProgressBar(tqdm):\n",
    "    def update_to(self, b=1, bsize=1, tsize=None):\n",
    "        if tsize is not None:\n",
    "            self.total = tsize\n",
    "        self.update(b * bsize - self.n)\n",
    "\n",
    "\n",
    "def download_url(url, output_path):\n",
    "    with DownloadProgressBar(unit='B', unit_scale=True,\n",
    "                             miniters=1, desc=url.split('/')[-1]) as t:\n",
    "        urllib.request.urlretrieve(url, filename=output_path, reporthook=t.update_to)\n",
    "\n",
    "def direct_file_download_open_neuro(file_list, file_types, dataset_id, dataset_version, save_dirs):\n",
    "    # https://openneuro.org/crn/datasets/ds004226/snapshots/1.0.0/files/sub-001:sub-001_scans.tsv\n",
    "    for i, n in enumerate(file_list):\n",
    "        subject = n.split('_')[0]\n",
    "        download_link = 'https://openneuro.org/crn/datasets/{}/snapshots/{}/files/{}:{}:{}'.format(dataset_id, dataset_version, subject, file_types[i],n)\n",
    "        print('Attempting download from ', download_link)\n",
    "        download_url(download_link, op.join(save_dirs[i], n))\n",
    "        print('Ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6213a5",
   "metadata": {},
   "source": [
    "First, this cell will download the events file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa4a7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_fmap = 'ds004226'\n",
    "subject_fmap = '001' \n",
    "\n",
    "# Download one subject's data from each dataset\n",
    "bids_root = op.join(op.dirname(sample.data_path()), dataset_fmap)\n",
    "\n",
    "mkdir_no_exist(bids_root)\n",
    "\n",
    "\n",
    "\n",
    "func_path = op.join(bids_root, 'sub-001', 'func')\n",
    "mkdir_no_exist(op.join(bids_root, 'sub-001'))\n",
    "mkdir_no_exist(func_path)\n",
    "\n",
    "direct_file_download_open_neuro(file_list=['sub-001_task-sitrep_run-04_events.tsv'], \n",
    "                                file_types=['func'], \n",
    "                                dataset_id=dataset_fmap, \n",
    "                                dataset_version='1.0.0', \n",
    "                                save_dirs=[func_path])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05acbd53",
   "metadata": {},
   "source": [
    "Now, we must load it. It has been placed into the functional folder of sub-001, given by the variable func_path. So to load it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7901ceff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(op.join(func_path, 'sub-001_task-sitrep_run-04_events.tsv'), sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67630ab5",
   "metadata": {},
   "source": [
    "Easy enough right? :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b87682e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
