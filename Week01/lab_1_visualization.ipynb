{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "Title"
    ]
   },
   "source": [
    "<img src=\"https://www.epfl.ch/about/overview/wp-content/uploads/2020/07/logo-epfl-1024x576.png\" style=\"padding-right:10px;width:140px;float:left\"></td>\n",
    "<h2 style=\"white-space: nowrap\">Neural Signals and Signal Processing (NX-421)</h2>\n",
    "<hr style=\"clear:both\"></hr>\n",
    "\n",
    "Welcome to the NX-421 class! In today's week, you will get to know Magnetic Resonance (MR) images.\n",
    "You will learn today how to visualize images, along with some basic manipulation of MRI data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "#####################\n",
    "# Import of utils.py functions\n",
    "#####################\n",
    "# Required to get utils.py and access its functions\n",
    "notebook_dir = os.path.abspath(\"\")\n",
    "parent_dir = os.path.abspath(os.path.join(notebook_dir, '..'))\n",
    "sys.path.append(parent_dir)\n",
    "sys.path.append('.')\n",
    "from utils import loadFSL, FSLeyesServer, mkdir_no_exist, interactive_MCQ\n",
    "\n",
    "####################\n",
    "# DIPY_HOME should be set prior to import of dipy to make sure all downloads point to the right folder\n",
    "####################\n",
    "os.environ[\"DIPY_HOME\"] = \"/home/jovyan/Data\"\n",
    "\n",
    "\n",
    "#############################\n",
    "# Loading fsl and freesurfer within Neurodesk\n",
    "# You can find the list of available other modules by clicking on the \"Softwares\" tab on the left\n",
    "#############################\n",
    "import lmod\n",
    "await lmod.purge(force=True)\n",
    "await lmod.load('fsl/6.0.7.4')\n",
    "await lmod.load('freesurfer/7.4.1')\n",
    "await lmod.list()\n",
    "\n",
    "####################\n",
    "# Setup FSL path\n",
    "####################\n",
    "loadFSL()\n",
    "\n",
    "###################\n",
    "# Load all relevant libraries for the lab\n",
    "##################\n",
    "import fsl.wrappers\n",
    "import mne_nirs\n",
    "import nilearn\n",
    "import mne\n",
    "import mne_nirs\n",
    "import dipy\n",
    "from dipy.data import fetch_bundles_2_subjects\n",
    "import xml.etree.ElementTree as ET\n",
    "import os.path as op\n",
    "import nibabel as nib\n",
    "from nilearn.datasets import fetch_development_fmri\n",
    "from fsl.wrappers import fslmaths\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def display_atlas_corresp(atlas_xml_path):\n",
    "    \"\"\"\n",
    "    Given a path to an XML, extract all region labels and print their correspondance with numerical values\n",
    "    of the nifti atlas file. (FSL-based convention)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    atlas_xml_path: string\n",
    "        Path to an XML atlas path, from which to extract all labels.\n",
    "    \"\"\"\n",
    "    root=ET.parse(atlas_xml_path).getroot()\n",
    "    for type_tag in root.findall('data/label'):\n",
    "        value = type_tag.get('index')\n",
    "        display('{} : {}'.format(int(value)+1, type_tag.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%gui wx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "Title"
    ]
   },
   "outputs": [],
   "source": [
    "################\n",
    "# Start FSLeyes (very neat tool to visualize MRI data of all sorts) within Python\n",
    "################\n",
    "fsleyesDisplay = FSLeyesServer()\n",
    "fsleyesDisplay.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "This week, you will get a bit more familiar with visualization tools to view MRI images, diffusion MR images and lastly atlas visualization. We will introduce the different tools on the fly, so that you get a good idea of how to use them for your projects!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Part 1: Visualization and some basic manipulation\n",
    "\n",
    "\n",
    "## 1.1. Visualization of MR images\n",
    "\n",
    "These images are typically in a very peculiar format: the <a href=\"https://brainder.org/2012/09/23/the-nifti-file-format/\">NIfTI file format</a>. You will notice that files have the .nii extension, or .nii.gz extension (which is nothing more than a compressed NIfTI file). While a full discourse on the format itself is a bit out of scope for this exercise, there are several things one should be aware of:\n",
    "- A NIfTI file under the hood comprises two things, a header, and an image. The header keeps informations on the acquisition, such as dimensions of the voxels used, number of slices for each dimension, TR, affine transformation, sequence parameters...Some scanners (specifically SIEMENS scanners) will also store in the header information about the timing acquisitions of each slice, which is particularly handy when you need to perform slice-timing correction. The image itself is the data that has been acquired: the 3D volume in the case of a structural MR image!\n",
    "- Because of its peculiar format and its 3D nature (for structurals again! a functional MRI would be 4D as it is a collection of 3D acquisitions), it is typically not possible to visualize them with usual image processing libraries such as ImageMagick: we need specialized software !\n",
    "\n",
    "In this course, we will use <a href=\"https://fsl.fmrib.ox.ac.uk/fsl/docs/#/\">FSL</a>.\n",
    "\n",
    "\n",
    "<div class=\"warning\" style='background-color:#90EE90; color: #112A46; border-left: solid #805AD5 4px; border-radius: 4px; padding:0.7em;'>\n",
    "<span>\n",
    "<p style='margin-top:1em; text-align:center'>\n",
    "<b><img src=\"imgs/fsl_logo.png\" width=\"150\"><br><center>FSL</center></b></p>\n",
    "<p style='text-indent: 10px;'>\n",
    "FSL (FMRIB Software Library) is a library of analysis and visualization used for MRI, fMRI and DTI. It is typically run through command line.<br>\n",
    "    FSL is not the only library available! <a href=\"https://afni.nimh.nih.gov/\">AFNI</a> and <a href=\"https://www.fil.ion.ucl.ac.uk/spm/\">SPM</a> are two such other libraries, to quote two of the most well known. They all offer different flexibilities and ways to program. As an example, SPM is mainly reliant on MATLAB, while AFNI is heavy on the command-line. To serve as an easy hand-on introduction, we are using FSL, because Python is a language with which most of you are likely to be familiar at some level. Note that should you wish to use the command line commands of FSL, you can get quite detailed into the steps you wish to apply.\n",
    "</p></span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "If all went well, FSLeyes should have opened as a new window. You will now witness the unlimited power of the interactive session. For now you should have something empty, ie it might look like this:\n",
    "<img src=\"imgs/fsleyes_empty.png\">\n",
    "<br>\n",
    "\n",
    "<div class=\"warning\" style='background-color:#C04000; color: #112A46; border-left: solid #C04000 4px; border-radius: 4px; padding:0.7em;'>\n",
    "<span>\n",
    "<p style='margin-top:1em; text-align:center'><b>‚ö†Ô∏è  DO NOT CLOSE FSLEYES ‚ö†Ô∏è </b></p>\n",
    "<p style='text-indent: 10px;'>\n",
    "    Whatever you do, do NOT close FSLeyes. Otherwise, you will have to restart the kernel to get it back (its widget context will be destroyed and unrecoverable).</p>\n",
    "</span>\n",
    "</div>\n",
    "\n",
    "### 1.1.1 First visualization\n",
    "\n",
    "We will add a first image in FSLeyes. This is done by specifying the absolute path to the image (in .nii or .nii.gz format !) \n",
    "\n",
    "In our case, we will start by showing a standard anatomical image: the brain in MNI space.\n",
    "This brain is located in the path $FSLDIR/data/standard/MNI512_T1_0.5mm.nii.gz\n",
    "Knowing this path, we can use FSLeyes load() function to directly load the image in the software interactively! \n",
    "Run the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fsleyesDisplay.load(op.expandvars('$FSLDIR/data/standard/MNI152_T1_0.5mm'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "You should see something that looks like this:\n",
    "<img src=\"imgs/mni_template_ex.png\">\n",
    "\n",
    "First of all, you should observe the specific contrast used: this is what is called a T1 contrast, typically used for anatomical scans. You will see later in the course why exactly it is called this way. For now, let's think about brain anatomy.\n",
    "\n",
    "Run the cell below and select the answer(s) which you deem correct (This is not graded, but merely for your curiosity and help you integrate the lab!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "interactive_MCQ(1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "Notice here we have picked a rather exquisite resolution: 0.5mm (meaning here a given voxel in 3D is 0.5 x 0.5 x 0.5 mm¬≥)! \n",
    "\n",
    "\n",
    "Every time you move in a direction, you move across what are called **slices**. \n",
    "\n",
    "\n",
    "Can you make out the different types of tissues in the brain, just at a glance? Try to pinpoint where the majority of grey matter is found, based on contrast only.\n",
    "\n",
    "\n",
    "Using your mouse, don't hesitate to play around the display a bit! Notice the 3-view display, showing in order sagittal, coronal and axial views of the brain. You can disable each view individually, by clicking on the appropriate buttons:\n",
    "<img src=\"imgs/fsl_view_buttons.png\"><br>\n",
    "\n",
    "\n",
    "On the **sagittal slice**, you can see two letters at each side of the brain: P and A, for Posterior and Anterior, respectively. Moving only along the sagittal axis, can you approximately guess where the eye sockets are? (Note: you are allowed to move only along the sagittal axis, but you can still look at the other views, especially the coronal view!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### 1.1.2 Atlases and brain masks \n",
    "\n",
    "FSL has many functionalities. When looking at brain data, one interesting aspect is the one of atlases: figuring out which region one is looking at is useful to answer neurological questions or even to perform sanity checks on your data. As an example, if your participants are involved in a clicking task but no activity is visible in motor areas, you're probably doing something wrong somewhere. But to detect this, you obviously need to be able to distinguish **where** motor areas are located! \n",
    "One of its most basic uses is the ability to overlay images on top of each other. To demonstrate this one, we will load an atlas on top of our brain. \n",
    "\n",
    "<div class=\"warning\" style='background-color:#90EE90; color: #112A46; border-left: solid #805AD5 4px; border-radius: 4px; padding:0.7em;'>\n",
    "<span>\n",
    "<p style='margin-top:1em; text-align:center'>\n",
    "<b>Atlases in MRI</b></p>\n",
    "<p style='text-indent: 10px;'>\n",
    "There are many atlases available, depending on your interest; some provide insight into subcortical structures, whereas others will partition the cortex. Atlases can be functional or anatomical, data-driven or labeled by experts, bilateral... All these choices will induce differences in the outlined regions, obviously. You should also be aware of the fact that atlases will provide you an image at the <b>population level</b> but will not be perfectly accurate at the subject level, since these are averages.\n",
    "\n",
    "\n",
    "In any case, an atlas is typically represented also as a NIfTI file. Each region in the atlas - a region of interest (ROI) - takes a <b>unique</b> value to distinguish from the others. A companion file usually indicates the correspondance between the value and the region.\n",
    "    \n",
    "<img src=\"imgs/atlas_example.png\">\n",
    "    <center><i>One example of an atlas. Notice the colors matching in each hemisphere: this atlas does not differentiate between the two hemispheres for its regions.</i></center>\n",
    "</p></span>\n",
    "</div>\n",
    "\n",
    "\n",
    "#### 1.1.2.1 Loading an atlas and visualizing its regions\n",
    "\n",
    "We will load our T1 (in 1mm resolution this time) and overlay an atlas image on top.\n",
    "The colormap of the atlas can be set, which allows us to better visualize the different regions. In the right inferior corner of FSLeyes, you can view the value of the voxel at which the green cross is centered.\n",
    "<img src=\"imgs/cross_value_fsleyes.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fsleyesDisplay.resetOverlays()\n",
    "fsleyesDisplay.load(op.expandvars('$FSLDIR/data/standard/MNI152_T1_1mm'))\n",
    "\n",
    "# Loads the atlas image\n",
    "fsleyesDisplay.load(op.expandvars('$FSLDIR/data/atlases/MNI/MNI-maxprob-thr25-1mm.nii.gz'))\n",
    "# Because there are two images in the list of overlays, the 2nd image being the atlas,\n",
    "# we can very easily target its colormap and change it like so:\n",
    "fsleyesDisplay.setOverlayCmap(1,'Render3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "The companion file can be found in the FSL directory of the atlases, in xml format.\n",
    "\n",
    "Here is the correspondance of values to regions in this atlas: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_atlas_corresp(op.expandvars('$FSLDIR/data/atlases/MNI.xml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "interactive_MCQ(1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### 1.1.2.2 Using atlases as masks\n",
    "\n",
    "Now that you understand how atlases are handled, we can move on to another interest topic: masking data with an atlas. This can become handy for several reasons, the first being if you want to analyze data coming from a specific region. The mask can be created either in Python or through FSL. We will teach you both, so that you can choose whichever method you prefer. Let us create a mask of the frontal lobe, as an example.\n",
    "\n",
    "##### Method 1: Python-based creation of the mask\n",
    "\n",
    "The steps are simple:\n",
    "1. Load the atlas as a regular file and extract the data as a numpy array\n",
    "2. Create a binary mask of the frontal lobe\n",
    "3. Write back to disk the mask with only the part of interest set to 1\n",
    "\n",
    "Just to make sure you're still following and not falling asleep, we've provided you with a function that does the above steps...But you need to call it with the proper arguments to extract the frontal lobe *and* give a name to the file! By default, the mask will be named mymask.nii.\n",
    "\n",
    "Lastly, to convince you that this mask is indeed the real deal, we will display it in FSLeyes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_mask_from_atlas(mask_value, mask_name=\"mymask.nii\"):\n",
    "    import numpy as np\n",
    "    # Load the atlas with nibabel\n",
    "    atlas = nib.load(op.expandvars('$FSLDIR/data/atlases/MNI/MNI-maxprob-thr25-1mm.nii.gz'))\n",
    "    # Extract the atlas data as a numpy array\n",
    "    atlas_data = atlas.get_fdata()\n",
    "    # The mask is set to true only in voxels which match the target mask_value\n",
    "    mask_data = atlas_data == mask_value\n",
    "    # Create a new nifti image with nibabel\n",
    "    mask_img = nib.Nifti1Image(mask_data.astype(np.uint8), atlas.affine, atlas.header)\n",
    "    # Save the image\n",
    "    if \".nii\" not in mask_name:\n",
    "        mask_name += '.nii.gz'\n",
    "    nib.save(mask_img, mask_name)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mask_name=???# Fill it with the name you want to give your mask!\n",
    "mask_value=??? # Fill it with the value of the region you want to extract from the atlas!\n",
    "make_mask_from_atlas(mask_value, mask_name)\n",
    "fsleyesDisplay.resetOverlays()\n",
    "fsleyesDisplay.load(op.expandvars('$FSLDIR/data/standard/MNI152_T1_1mm'))\n",
    "fsleyesDisplay.load(mask_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "##### Method 2: FSL-based creation of the mask\n",
    "\n",
    "Again the steps are not too hard! You simply need to apply exactly the logic we have applied in method 1 to take the atlas, set all values of interest to 1 and the rest to zero. We will do so using a simple method: we will lower threshold the image, setting to zero anything **below** the provided threshold. Then, we will set anything **above** a second threshold to zero. Anything that is non zero by this point, we will set to 1.\n",
    "\n",
    "\n",
    "We provide you with a simple function that accepts the two thresholds described above, named lower_threshold and upper_threshold. Decide on their value so as to extract again the *frontal lobe*. Likewise, the function will by default save the file as mymask.nii. Feel free to give it a more explicit name!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_mask_from_atlas_fsl(lower_threshold, upper_threshold, mask_name=\"mymask.nii\"):\n",
    "    fslmaths(op.expandvars('$FSLDIR/data/atlases/MNI/MNI-maxprob-thr25-1mm.nii.gz')).thr(lower_threshold).uthr(upper_threshold).bin().run(mask_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mask_name=\"other_mask.nii.gz\"\n",
    "lower_threshold=??? # Fill me\n",
    "upper_threshold=??? # Fill me\n",
    "make_mask_from_atlas_fsl(lower_threshold, upper_threshold, mask_name)\n",
    "\n",
    "fsleyesDisplay.resetOverlays()\n",
    "fsleyesDisplay.load(op.expandvars('$FSLDIR/data/standard/MNI152_T1_1mm'))\n",
    "fsleyesDisplay.load(glob.glob(mask_name + '*')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 1.2. Viewing functional MR images\n",
    "\n",
    "What you've learnt so far in visualization can very easily be applied to fMRI images. To showcase this, we will load one fMRI session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "interactive_MCQ(1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fsleyesDisplay.resetOverlays()\n",
    "fsleyesDisplay.load(fetch_development_fmri(n_subjects=1, verbose=1, age_group='both', data_dir=\"/home/jovyan/Data/\")['func'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Please pay attention to the fMRI's voxel dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'Dimensions: ' + ' x '.join([str(i) + 'mm' for i in  nib.load(fetch_development_fmri(n_subjects=1, verbose=1, age_group='both')['func'][0]).header.get_zooms()])[:-2] + 's'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Do they match what you would expect? Compared to the anatomical you have seen so far, why do you think we observe such a difference in resolution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "The answer is simple: fMRI trades spatial resolution for temporal resolution, as you have seen in class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "interactive_MCQ(1,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### 1.2.1 fMRI as a movie\n",
    "\n",
    "As you've no doubt noticed, FSLeyes has one little sneaky button: the movie button!\n",
    "If you click on it, it will start to play the fMRI recording as a movie, allowing you to appreciate how the signal is fluctuating across time!\n",
    "\n",
    "\n",
    "<div class=\"warning\" style='background-color:#90EE90; color: #112A46; border-left: solid #805AD5 4px; border-radius: 4px; padding:0.7em;'>\n",
    "<span>\n",
    "<p style='margin-top:1em; text-align:center'>\n",
    "<b>üêû Troubleshooting: fMRI movie is flickering üêû</b></p>\n",
    "<p style='text-indent: 10px;'>\n",
    "    \n",
    "If you enable the movie with FSLeyes synchronized with Python, you might not see a very pleasant movie, but more something along the lines of dark flickers with some occasional brains appearing in between.\n",
    "<img src=\"imgs/buggy_fmri_display.gif\">\n",
    "    \n",
    "This happens because FSLeyes is attempting to synchronize with Python and - well, there is a sluggish response between the two. Alleviating this behaviour is very easy! Simply disable the <b>Synchronize movie updates</b> option:\n",
    "<img src=\"imgs/settings_button.png\">\n",
    "    <center><i>Click on the settings</i></center>\n",
    "<img src=\"imgs/settings_menu.png\">\n",
    "    <center><i>Make sure to uncheck the Synchronize movie updates option</i></center>\n",
    "\n",
    "</p></span>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 1.3. Viewing diffusion MR images\n",
    "\n",
    "Now that you are a bit familiar with FSLeyes, you should know you can also view other modalities, besides anatomical MR images with FSL; you can view functional data, but also diffusion weighted MR images!\n",
    "We will show you how to view the fibers for an examplar dataset available in the DIPY library - a library specialized in diffusion imaging.\n",
    "\n",
    "DIPY offers other visualizations that might interest you, so feel free to have a look in their <a href=\"https://workshop.dipy.org/documentation/1.7.0/examples_built/\">documentation</a>.\n",
    "\n",
    "The first step is to download the subjects tracts. Then, we simply display them in FSLeyes, overlayed on top of the subject T1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_bundle = fetch_bundles_2_subjects()[1] # Download bundles of two subjects provided by dipy\n",
    "\n",
    "files = glob.glob(op.join(path_bundle, \"bundles_2_subjects/subj_1/bundles/*.trk\")) # List all the tracts of the subject\n",
    "fsleyesDisplay.resetOverlays()\n",
    "fsleyesDisplay.load(op.join(path_bundle, \"bundles_2_subjects/subj_1/t1_warped.nii.gz\")) # Get the subject t1 to show it as background\n",
    "[fsleyesDisplay.load(f) for f in files] # Loop through all tracts of the subject and load them in FSLeyes\n",
    "print(\"Done loading all fibers, look at FSLeyes (wait for a few seconds if you see nothing but black, FSLeyes is loading everything ;) )\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "üéâ You've reached the end of this week's notebook! Congratulations! üéâ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "toc": {
   "base_numbering": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
