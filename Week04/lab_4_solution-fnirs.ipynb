{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0005f9d3-e329-4837-918e-9df0b384489e",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<img src=\"https://www.epfl.ch/about/overview/wp-content/uploads/2020/07/logo-epfl-1024x576.png\" style=\"padding-right:10px;width:140px;float:left\"></td>\n",
    "<h2 style=\"white-space: nowrap\">Neural Signals and Signal Processing (NX-421)</h2>\n",
    "<hr style=\"clear:both\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775a8a63-df82-4cae-b9d1-f28fcec4f71b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Welcome to the laboratory computers for the course \"Neural signals and signal processing\". \n",
    "This week, we finish up the preprocessing of fMRI on some advanced points, which you might need when working on your mini-project.\n",
    "We will then look at functional Near Infrared Spectroscopy (fNRIS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b7844c-199f-423c-9336-eef343b02430",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%gui wx\n",
    "import sys\n",
    "import os\n",
    "\n",
    "#####################\n",
    "# Import of utils.py functions\n",
    "#####################\n",
    "# Required to get utils.py and access its functions\n",
    "notebook_dir = os.path.abspath(\"\")\n",
    "parent_dir = os.path.abspath(os.path.join(notebook_dir, '..'))\n",
    "sys.path.append(parent_dir)\n",
    "sys.path.append('.')\n",
    "from utils import loadFSL, FSLeyesServer, mkdir_no_exist, interactive_MCQ,get_json_from_file\n",
    "\n",
    "####################\n",
    "# DIPY_HOME should be set prior to import of dipy to make sure all downloads point to the right folder\n",
    "####################\n",
    "os.environ[\"DIPY_HOME\"] = \"/home/jovyan/Data\"\n",
    "\n",
    "\n",
    "#############################\n",
    "# Loading fsl and freesurfer within Neurodesk\n",
    "# You can find the list of available other modules by clicking on the \"Softwares\" tab on the left\n",
    "#############################\n",
    "import lmod\n",
    "await lmod.purge(force=True)\n",
    "await lmod.load('fsl/6.0.7.4')\n",
    "await lmod.load('freesurfer/7.4.1')\n",
    "await lmod.list()\n",
    "\n",
    "####################\n",
    "# Setup FSL path\n",
    "####################\n",
    "loadFSL()\n",
    "\n",
    "###################\n",
    "# Load all relevant libraries for the lab\n",
    "##################\n",
    "import fsl.wrappers\n",
    "from fsl.wrappers import fslmaths\n",
    "\n",
    "import mne_nirs\n",
    "import nilearn\n",
    "from nilearn.datasets import fetch_development_fmri\n",
    "\n",
    "import mne\n",
    "import mne_nirs\n",
    "import dipy\n",
    "from dipy.data import fetch_bundles_2_subjects, read_bundles_2_subjects\n",
    "import xml.etree.ElementTree as ET\n",
    "import os.path as op\n",
    "import nibabel as nib\n",
    "import glob\n",
    "\n",
    "import ants\n",
    "import openneuro\n",
    "from mne.datasets import sample\n",
    "from mne_bids import BIDSPath, read_raw_bids, print_dir_tree, make_report\n",
    "\n",
    "\n",
    "# Useful imports to define the direct download function below\n",
    "import requests\n",
    "import urllib.request\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# FSL function wrappers which we will call from python directly\n",
    "from fsl.wrappers import fast, bet\n",
    "from fsl.wrappers.misc import fslroi\n",
    "from fsl.wrappers import flirt\n",
    "\n",
    "# General purpose imports to handle paths, files etc\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from IPython.display import display, HTML\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe243d82-cc8d-4de7-816e-b2062e71af99",
   "metadata": {},
   "source": [
    "NOTE: Do not worry if you get the message \"Gtk-Message: 09:26:08.207: Failed to load module \"canberra-gtk-module\", the Notebook will still work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dff04c6-e097-450c-8ae2-033f9cabb72b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Inject custom CSS\n",
    "custom_css =\"\"\"\n",
    "<style>\n",
    "\n",
    "  .fit {\n",
    "    object-fit: cover;\n",
    "  }\n",
    "\n",
    "  .container {\n",
    "    display: flex;\n",
    "    align-items: center; /* Align blocks vertically in the middle */\n",
    "    justify-content: flex-start; /* Align blocks to the left */\n",
    "  }\n",
    "\n",
    "  .imageDiv {\n",
    "      background: #fff;\n",
    "      display: block;height: 150px;width: 150px;padding: 10px;border-radius: 2px;box-shadow: 0 1px 4px rgba(0, 0, 0, 0.3), 0 0 40px rgba(0, 0, 0, 0.1) inset;flex-shrink: 0;\n",
    "  }\n",
    "    .arrow-right {\n",
    "      width: 0; \n",
    "      height: 0; \n",
    "      border-top: 1em solid transparent;\n",
    "      border-bottom: 1em solid transparent;\n",
    "      border-left: 1em solid #000;\n",
    "    }\n",
    "      .col-md-10 {\n",
    "        display: flex;\n",
    "        align-items: center;\n",
    "      }\n",
    "    \n",
    "    .bby {\n",
    "        display: flex;\n",
    "        justify-content: center;\n",
    "        align-items: center;\n",
    "        height: 100vh;\n",
    "        font-family: Arial, sans-serif;\n",
    "    }\n",
    "    \n",
    "    .flow-container {\n",
    "        display: flex;\n",
    "        align-items: center;\n",
    "        justify-content:center;\n",
    "    }\n",
    "    \n",
    "    .box-text-container {\n",
    "        flex-direction: column;\n",
    "        display: center;\n",
    "        align-items: center;\n",
    "        justify-content:center;\n",
    "    }\n",
    "    \n",
    "    .step-box {\n",
    "        background-color: lightgray;\n",
    "        padding: 0.5em;\n",
    "        margin: 0 0.5em;\n",
    "        text-align: center;\n",
    "        font-weight: bold;\n",
    "        border-radius: 0.25em;\n",
    "        border: 0.15em solid black;\n",
    "        min-width: 6em;\n",
    "    }\n",
    "    \n",
    "    .arrow {\n",
    "        font-size: 1.5em;\n",
    "        color: blue;\n",
    "        font-weight: bold;\n",
    "        margin: 0 0 0.5em;\n",
    "    }\n",
    "    \n",
    "    .text {\n",
    "        font-weight: bold;\n",
    "        font-size: 0.9em;\n",
    "        margin: 0 0.5em;\n",
    "    }\n",
    "    \n",
    "    .box-wrapper {\n",
    "        display: flex;\n",
    "        align-items: center;\n",
    "        padding: 0.5em;\n",
    "        border: 0.15em solid black;\n",
    "        border-radius: 10px;\n",
    "    }\n",
    "    \n",
    "    /* Style for the text below the box */\n",
    "    .kapt_2 {\n",
    "        margin-top: 0.5em;\n",
    "        font-size: 1em;\n",
    "        font-weight: bold;\n",
    "    }\n",
    "\n",
    "    .disp_p {\n",
    "        font-size:2.5em;\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(custom_css))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0fdce3-a223-479f-b6ce-d14af6a17285",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Part 2: Get acquainted with fNIRS data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39a5f92-f5c6-419f-8e53-5ce8922d4a22",
   "metadata": {},
   "source": [
    "In contrast to functional magnetic resonance imaging (fMRI), functional Near-Infrared Spectroscopy (fNIRS) distinguishes itself with portability and adaptability, making it especially suitable for research involving intricate populations like infants, tasks characterized by motion, and real-world settings.\n",
    "\n",
    "Nevertheless, it is important to acknowledge that collecting fNIRS data requires rigorous preprocessing. This requirement arises from fNIRS's susceptibility to 1) superficial physiological interferences, such as those stemming from scalp blood flow and 2) motion artifacts, especially those resulting from sensor displacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfee3ae-6594-4c31-9c6d-a91e65d8ab4e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os.path as op\n",
    "from mne.preprocessing.nirs import temporal_derivative_distribution_repair"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405ddcbc-ad58-46b9-99e1-955885332020",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 2.1 Data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b3c43f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### 2.1.1 Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3790ca-1acb-48e1-bb57-61c2d4200991",
   "metadata": {},
   "source": [
    "We will work on a set of hemodynamic data measured on one subject during a finger tapping paradigm with three conditions: 1) Tapping the left thumb to fingers, 2) Tapping the right thumb to fingers and 3) A control when nothing happens. Each tapping lasts 5 seconds and there are 30 trials in each condition.The recording was performed using fNIRS sensors located over motor areas of the cortex. \n",
    "\n",
    "Data were provided by Luke, R., & McAlpine, D. (2021). fNIRS Finger Tapping Data in BIDS Format (Version v0.0.1) (https://doi.org/10.5281/zenodo.5529797),"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ba5d71",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### 2.1.2 Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65eca6c2-6752-42d0-8a72-c641a7172cd4",
   "metadata": {},
   "source": [
    "Load the dataset by running the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7319ed",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import mne\n",
    "import os.path as op\n",
    "#Download dataset\n",
    "fnirs_data_folder = mne.datasets.fnirs_motor.data_path(path='/home/jovyan/Data/mne_data/')\n",
    "#Get the path for the dataset folder \n",
    "fnirs_data_folder=op.join(fnirs_data_folder, 'Participant-1')\n",
    "#Load the dataset \n",
    "raw_intensity = mne.io.read_raw_nirx(fnirs_data_folder, verbose=True, preload=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b267d19",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### 2.1.3 Recording setting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c16446-b605-4aef-b3d6-c4481d1d2b34",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Display and read information on the recording setting such as the number of channels, the file duration and the sampling frequency by runing the next cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa256c1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Display recording setting\n",
    "raw_intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdfaeb0-5c44-4216-bd66-333ad86f90dc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "interactive_MCQ(4,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0d3ad9-382b-49ab-9d4a-4a9becbc7bb9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "The placement of fNIRS sensors holds significance for achieving **a good spatial resolution** and an **accurate sensor placement**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374edb6c",
   "metadata": {},
   "source": [
    "Let's take a look at the locations of sensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c2c76c-0689-4224-940f-36790c5e2e7d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install \"pyvista[jupyter]\"\n",
    "!pip install pyvistaqt\n",
    "!pip install pyqt5\n",
    "!pip install qtconsole pyqt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8916c88b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib qt5\n",
    "subjects_dir = op.join(mne.datasets.sample.data_path('/home/jovyan/Data/mne_data'), \"subjects\")\n",
    "\n",
    "brain = mne.viz.Brain(\n",
    "subject=\"fsaverage\", subjects_dir=subjects_dir, background=\"black\", cortex=\"0.5\"\n",
    ")\n",
    "brain.add_sensors(\n",
    "    raw_intensity.info,\n",
    "    trans=\"fsaverage\",\n",
    "    fnirs=[\"channels\", \"pairs\", \"sources\", \"detectors\"],\n",
    ")\n",
    "brain.show_view(azimuth=20, elevation=60, distance=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3570f4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<p style=\"color:green\"> See below the expected 3D visualization of the fNIRS sensors placed over the head: </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c88544-584c-4965-8d65-e9e9a34112d8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<img src=\"imgs/3Dmap.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08096f8",
   "metadata": {},
   "source": [
    "In the 3D visualization, we represent source-detector pairs or channels as lines. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd23aec-dbc9-458b-a5de-1bd8f32cb952",
   "metadata": {},
   "source": [
    "<span style=\"color:blue; text-decoration:underline;\">Multiple Choice Question</span>\n",
    "\n",
    "*What is the cortical region covered by this measurement ?*\n",
    "1. Motor cortex\n",
    "2. Visual cortex\n",
    "\n",
    "   <p style=\"color:green\"> In this finger tapping task, sensors are placed over the motor cortex. This region is located in the dorsal portion of the frontal lobe. </p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc93e0b",
   "metadata": {},
   "source": [
    "### 2.1.4 Experimental design"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89c02f5-2d5a-44e7-9c09-9b17f0690c1b",
   "metadata": {},
   "source": [
    "Let's now have a look at the experimental design used.\n",
    "\n",
    "The experimental designs most commonly employed by auditory fNIRS researchers are block- and event-related designs. In an event related design, each task is presented individually for a short amount of time e.g., 3 seconds. In this way, tasks can be more  randomized,  rather  than  being  blocked  together  by  condition. Conversely, in a block-related design, blocks of tasks, each lasting at least 10 seconds, recur before intervals of rest. \n",
    "\n",
    "The choice of the experimental design depends on a range of factors, including the statistical power, the duration of the experiment, and whether the design provides the flexibility to study the effect of interest. While the block design might lead to higher detection power, it can also induce learning and boredom effects which may bias the results. On the other hand, event-related designs reduce the effects of learning, boredom while exhibiting loss in detection power. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bd3413",
   "metadata": {},
   "source": [
    "<span style=\"color:blue; text-decoration:underline;\">Open question</span>\n",
    "\n",
    "*What are the analytical challenges associated with employing a block-related experimental design featuring continuous stimulation and brief rest blocks?*\n",
    "\n",
    "   <p style=\"color:green\"> In a block-related experimental design with continuous stimulation and brief rest blocks, we can end-up having a non-linear summation of the hemodynamic responses to stimuli. This non-linearity can cause a mismatch between the predicted  summation of responses obtained with linear approaches (e.g., averaging or general linear modelling) and the actual observed data. </p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df6d506-59bc-4300-b1ec-e0b55747c4f7",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Run the next cell to display the sequence of events used in this experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9690b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the event annotations\n",
    "events, event_dict=mne.events_from_annotations(raw_intensity,verbose=False)\n",
    "#Assign each label to the event (based on recording setting)\n",
    "event_dict={'Control':1,'Tapping/Left':4,'Tapping/Right':3,'ExperimentEnds':2}\n",
    "#Display the sequence of events \n",
    "plt.rcParams[\"figure.figsize\"]=(10,6)\n",
    "mne.viz.plot_events(events,event_id=event_dict,sfreq=raw_intensity.info['sfreq']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f213d4ad-e49f-4cf3-b4ab-c4ef1cb6ef0a",
   "metadata": {},
   "source": [
    "As you can see, there is a significant gap or interstimulus interval between each individual stimulus. We can thus conclude that an event-related design was employed in this experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb2a3f7-feec-4b81-8128-9ed70614ab17",
   "metadata": {},
   "source": [
    "Now that we have gained an understanding of the experiment and recording processes, we can start the visualization of the raw data collected. To proceed, run the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bbf747",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a figure window\n",
    "plt.rcParams[\"figure.figsize\"]=(40,40)\n",
    "#Plot time-series of raw light intensity data \n",
    "mne.viz.plot_raw(raw_intensity,start=120,duration=80,n_channels=56,show_scrollbars=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f687ea7c",
   "metadata": {},
   "source": [
    "In this plot, we can observe the time-series of the data collected, represented as the change in light intensity resulting from light absorption at specific wavelengths. Oxygenated hemoglobin (HbO) absorbs light at \"850\"nm, while deoxygenated hemoglobin (HbR) absorbs light at \"760\"nm. Each channel comprises a pair consisting of a source (labeled as \"S\" in the plot) and a detector (labeled as \"D\" in the plot). \n",
    "\n",
    "Here, we are showing all the channels (y-axis) but, for clarity, we are only focusing on a specific timeframe, spanning from 120 to 200 seconds (x-axis). If you wish to customize the visualization parameters, please refer to the documentation of [mne.viz.plot_raw](https://mne.tools/stable/generated/mne.viz.plot_raw.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33907f00",
   "metadata": {},
   "source": [
    "<span style=\"color:blue; text-decoration:underline;\">Open question</span>\n",
    "\n",
    "*Visually, are you able to localize a motion artifact?*\n",
    "\n",
    "   <p style=\"color:green\"> There are two types of motion artefacts we can visualize in this graph: a spike between 185-190s and a baseline shift in the S8_D8 850 channel. These two types of artefact can easily happen in motor tasks. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a23001d",
   "metadata": {},
   "source": [
    "## 2.2 Preprocess the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdcd271",
   "metadata": {},
   "source": [
    "A typical preprocessing pipeline for fNIRS data includes the following key steps:\n",
    "\n",
    "<hr>\n",
    "\n",
    "*Step 1: Raw Intensity to Optical Density Conversion*\n",
    "\n",
    "<hr> \n",
    "\n",
    "*Step 2: Motion Artifact Removal*\n",
    "\n",
    "<p style='margin-top:1em;'>ðŸ’¡ This step is more effective when performed at the beginning of the pipeline to prevent the propagation of errors across wavelengths and minimizes cross talk between signals obtained at different wavelengths.\n",
    "\n",
    "<hr> \n",
    "\n",
    "*Step 3: Optical Density to Concentration Conversion*\n",
    "\n",
    "<hr>\n",
    "\n",
    "*Step 4: Physiological Oscillation Filtering*\n",
    "\n",
    "<p style='margin-top:1em;'>ðŸ’¡ This step is more effective when performed after the conversion step using the modified Beer-Lambert law, as physiological sources of error impact HbO and HbR in a manner consistent with the Beer-Lambert equation.\n",
    "    \n",
    "    \n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254195bd",
   "metadata": {},
   "source": [
    "### 2.2.1 Converting raw intensity data to optical density"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2b268b",
   "metadata": {},
   "source": [
    "The first step is to convert the changea in light intensity into changes in optical density using the modified Beer-Lambert law (Eq 1). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1547df8e-0e72-45ec-8e38-4ac81da9f2fd",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "OD_\\lambda - OD_{R\\lambda} = log\\frac{I_o}{I} (1)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386e0262-9fb3-4f55-9644-d980fa138240",
   "metadata": {},
   "source": [
    "With:\n",
    "- $OD_\\lambda$ the optical density of the medium for a given wavelength $\\lambda$\n",
    "- $OD_{R\\lambda}$ the optical density of light scattering within human tissue\n",
    "- $I_o$ the incident light intensity \n",
    "- $I$ the transmitted light intensity "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f7931b-3449-4789-8ca1-49f54afa377e",
   "metadata": {},
   "source": [
    "Run the next cell to convert raw intensity into optical density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7e624f-b7bb-4f19-8da6-6480a56cbe19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert raw intensity into optical density data\n",
    "raw_od=mne.preprocessing.nirs.optical_density(raw_intensity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4541499a",
   "metadata": {},
   "source": [
    "### 2.2.2 Correcting motion artefacts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1921d012",
   "metadata": {},
   "source": [
    "In fNIRS data, two types of artifacts are commonly encountered: baseline shifts (indicating sensor displacement without returning to the initial position) and spike artifacts (characterized by sensor oscillations). As you correctly guessed earlier, the abrupt shift occurring around ~190 seconds in the time-series plot above corresponds to a spike artifact."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b5a755",
   "metadata": {},
   "source": [
    "Here, we will employ a technique known as Temporal Derivative Distribution Repair (TDDR), which is designed to address motion artefacts. TDDR uses the temporal derivative of the signal to correct the signal. \n",
    "\n",
    "For a more comprehensive understanding of the TDDR method and its application, you can refer to the following paper:\n",
    "- Frank A. Fishburn, Ruth S. Ludlum, Chandan J. Vaidya, and Andrei V. Medvedev. \"Temporal Derivative Distribution Repair (TDDR): A Motion Correction Method for fNIRS.\" NeuroImage, 184:171â€“179, 2019. doi:10.1016/j.neuroimage.2018.09.025."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e26b3a",
   "metadata": {},
   "source": [
    "Run the cell below to apply the TDDR on the optical density data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3c457b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply TDDR on optical density data\n",
    "raw_od_preproc=temporal_derivative_distribution_repair(raw_od)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3346e30e",
   "metadata": {},
   "source": [
    "Execute the following cell to visualize the optical density data after applying TDDR. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0b8f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a figure window\n",
    "plt.rcParams[\"figure.figsize\"]=(40,40)\n",
    "#Plot time-series of optical density data following TDDR application\n",
    "mne.viz.plot_raw(raw_od_preproc,show_scrollbars=False,start=120,n_channels=56,duration=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f3546a",
   "metadata": {},
   "source": [
    "<span style=\"color:blue; text-decoration:underline;\">Open question</span>\n",
    "\n",
    "*From a visual standpoint, can we conclude that TDDR successfully eliminated the motion artifacts from your data?*\n",
    "\n",
    " <p style=\"color:green\"> While the TDDR corrected the baseline shift seen in some of the channels (e.g., S8_D8 850) it did not remove the spikes from the signal. This low sensitivity to motion-related spikes is actually one of the limits of the TDDR method. More robust methods that are however not proposed in mne-nirs library are the wavelet filtering or the spline interpolation.                                                                                                               For a comparison of motion artefact correction techniques, you can refer to the following paper:\n",
    "    Cooper, R. J., Selb, J., Gagnon, L., Phillip, D., Schytz, H. W., Iversen, H. K., ... & Boas, D. A. (2012). A systematic comparison of motion artifact correction techniques for functional near-infrared spectroscopy. Frontiers in neuroscience, 6, 147.</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fad549",
   "metadata": {},
   "source": [
    "### 2.2.3 Converting optical density to concentration "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a3a0f4",
   "metadata": {},
   "source": [
    "The changes in optical density are then converted into changes of concentration using the modified beer lambert law (Eq 1): "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f46ed4b",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\Delta c = \\frac{\\Delta OD_\\lambda }{\\epsilon_\\lambda lB} \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c91a1f2",
   "metadata": {},
   "source": [
    "Whith:\n",
    "- $\\Delta$ c the molar concentration change (in M)\n",
    "- $\\epsilon_\\lambda$ the moral absorption coefficient (in $M^-1 cm^-1$) for a given wavelength $\\lambda$\n",
    "- l the the optical pathlength \n",
    "- B the pathlength correction factor\n",
    "\n",
    "For more information on the equation, see the reference: Delpy DT, Cope M, Zee P van der, Arridge S, Wray S, Wyatt J. Estimation of optical pathlength through tissue from direct time of flight measurements. Phys Med Biol 1988; 33: 1433-1442."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118f1a01",
   "metadata": {},
   "source": [
    "Run the cell below to compute the concentration changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5957ebae-707c-46b7-b342-41d81f33356c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required beer-lambert law related function\n",
    "from mne.preprocessing.nirs import beer_lambert_law\n",
    "#Convert optical density into concentration change (hemodnyamic data)\n",
    "raw_haemo=beer_lambert_law(raw_od_preproc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875fc5db",
   "metadata": {},
   "source": [
    "### 2.2.4 Filtering out physiological oscillations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba952ae1-d0dc-4962-89bf-8a3aa842eea4",
   "metadata": {},
   "source": [
    "Let's now filter out physiological oscillations.\n",
    "\n",
    "To begin, we'll assess the extent of physiological oscillations within the data using power spectral density (PSD) analysis. Based on the sequence of events outlined previously, we note that stimuli for a same condition (e.g., tapping right) are presented at a rate of approximately once every 1/100 seconds. Consequently, we should anticipate a hemodynamic response to this specific stimulus occurring at this particular frequency. Any additional components identified in the PSD analysis can be attributed to other forms of oscillations, including physiological ones.\n",
    "\n",
    "Run the following cell to initiate the signal decomposition process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18baecef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the PSD of non-filtered hemodynamic data \n",
    "fig = spectrum = raw_haemo.compute_psd().plot(average = True)\n",
    "fig.suptitle('Before filtering', weight='bold', size='x-large')\n",
    "fig.subplots_adjust(top=0.88)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df54679-bb1a-4005-bb96-248cd96b2b8b",
   "metadata": {
    "tags": []
   },
   "source": [
    "The PSD shows a very low peak which may correspond to the hemodynamic responses to task stimulations. On the other hand, the presence of a frequency peak at 1.25 Hz aligns with the heart rate. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8ac0a6-3c4b-4e03-b7ac-389dc8a01cb8",
   "metadata": {},
   "source": [
    "Based on the information provided, apply a low-pass filter to retain only the hemodynamic responses. You may need to utilize the filter method available in the mne.io.Raw class as outlined in the MNE documentation (https://mne.tools/stable/generated/mne.io.Raw.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364095b0",
   "metadata": {},
   "source": [
    "<p style=\"color:green\"> MNE library provides two methods for filtering raw data: filter_data() function or the method filter. Here, we will utilize the filter() method, as it is more user-friendly and integrates seamlessly with subsequent analysis steps. \n",
    "\n",
    "<p style=\"color:green\"> In the context of event-related designs, the goal is to extract hemodynamic responses to specific events. In our case, we aim to compare the hemodynamic responses to different events. \n",
    "Therefore, we have three distinct signals of interest: hemodynamic responses to 1) tapping left, 2) tapping right, and 3) control events. Maintaining the stimulation frequency in these signals is crucial. To determine this stimulation frequency, \n",
    "refer to the event sequence above. You'll notice there is around 1 stimulation per 100 seconds for each event. \n",
    "In the power spectrum above, you can identify a peak at approximately 0.01Hz, likely associated to this event-related hemodynamic response. You may also want to get rid of physiological oscillations: among the most important, there is the heart rate at ~1Hz and the breathing rate at ~0.3Hz. You can see the corresponding peaks in the PSD above. Based on this, the upper pass-band edge of your low pass filter can be set to 0.2Hz. You can use transbandwidth to make a smooth transition between the passband (0.2Hz) and the stopband (0.3Hz, frequency above which you will get your signal contaminated by physiological oscillations). Filters with narrow transition bandwidths are often preferred in applications where closely spaced frequency components need to be separated such as ours. However, be aware that you cannot narrow too much the transition bandwidth with low-order filters as the ones proposed by MNE library.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db449cd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###########\n",
    "# Now apply the filter method to retain only the hemodynamic responses from your signal\n",
    "##########\n",
    "\n",
    "#And now, let's try to filter the hemodynamic data using the filter method for raw objects \n",
    "raw_haemofiltered=raw_haemo.filter(0, 0.2, h_trans_bandwidth=0.1,\n",
    "                             l_trans_bandwidth=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67022520",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"warning\" style='background-color:#C1ECFA; color: #112A46; border-left: solid darkblue 4px; border-radius: 4px; padding:0.7em;'>\n",
    "<span>\n",
    "<p style='margin-top:1em; text-align:center'><b>ðŸ’¡ Pay attention! ðŸ’¡</b></p>\n",
    "<p style='text-indent: 10px;'> Whenever you apply a filter, you should check that you are not removing the signal of interest. For that, make sure the task stimulation frequency is not within the frequency range of your filter ! </p>\n",
    "</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd00034-147c-46d0-80cc-c31d1e2a2332",
   "metadata": {},
   "source": [
    "Run the next cell to plot the PSD of your filtered data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c98f622",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the spectrum of filtered hemodynamic data \n",
    "fig = spectrum = raw_haemofiltered.compute_psd().plot(average = True)\n",
    "fig.suptitle('After filtering', weight='bold', size='x-large',y=1.1)\n",
    "fig.subplots_adjust(top=0.88)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff134ca",
   "metadata": {},
   "source": [
    "Run the next cell to visualize the filtered data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe26e841",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot time-series of hemodynamic data obtained with one channel \n",
    "raw_haemofiltered.plot(start=0,duration=200,n_channels=1,show_scrollbars=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721ff740-756b-44cc-8c8b-3074c0e5dc6c",
   "metadata": {},
   "source": [
    "Congratulations ! You now have all the basics to understand and preprocess fNIRS data!  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac02d6a-d896-48e0-a36c-e280f83b37df",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<p><b>ðŸŽ‰ You've reached the end of this week's notebook! Congratulations! ðŸŽ‰ </b></p>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
